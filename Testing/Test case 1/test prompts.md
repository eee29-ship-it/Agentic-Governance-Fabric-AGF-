# Scenario 2: High-Risk AI System – Patient Diagnosis Assistant

**Objective:**  
Test that the orchestrator correctly handles a high-risk AI system, triggering multiple subagents (Accuracy & Robustness, Human Oversight, Risk Management, Post-Market Monitoring, Transparency, etc.), collects required user inputs, and produces a fully traceable EU AI Act compliance report.

The AI system under audit is a high-risk diagnostic assistant (*DiagBot*) that handles sensitive personal health data and provides automated medical recommendations.

---

## Step 1: Initial System Description

**Orchestrator Prompt:**  
> Hi! Let’s start auditing your AI system for EU AI Act compliance. Could you describe your system, its purpose, and share a few example user interactions?

**User Input:**  
> The system is called *DiagBot*, an AI that provides automated preliminary medical diagnoses based on patient symptoms and medical history. It **does store personal health data** and can directly suggest possible conditions. Example interactions:  
> 1. User: “I have chest pain and shortness of breath.”  
> System: “You might be experiencing a cardiac event. Please seek emergency care immediately.”  
> 2. User: “I feel dizzy and have high blood pressure.”  
> System: “You may have hypertension complications. Schedule an urgent doctor visit.”


**Expected Risk Assessment Output (Simulated):**  
The Risk Assessment Subagent has identified **DiagBot** as a **High-Risk AI system**, triggering several compliance areas under the EU AI Act. These areas include:

- Risk Management System
- Data Governance and Management
- Technical Documentation
- Record-keeping (Logging)
- Transparency and Provision of Information to Users
- Human Oversight
- Accuracy, Robustness, and Cybersecurity
- Conformity Assessment
- Quality Management System
- Post-Market Monitoring


---

## Step 2: Data Governance Subagent

**Orchestrator Prompt:**  
> Given these findings, I will now proceed to call the relevant specialized subagents **in sequence** to audit DiagBot's compliance.

First, I will call the **Data Governance & Quality Subagent**, as proper data governance is crucial for a medical diagnosis system.

Before I do that, I need to ask you for the **structured dataset metadata** (sources, types, volumes) in **JSON format** that the Data Governance & Quality Subagent requires.


**User Input:**  
> The user attatches DiagBot_dataset_metadata.txt

**Expected Output:**  
Okay, I have received the detailed output from the Data Governance & Quality Subagent. Here's a summary:

- Overall Compliance: The subagent identified several areas of concern regarding data completeness, accuracy, bias, and documentation.
- Key Findings:
> Insufficient detail on missing value imputation and handling.
> Lack of consistency checks for categorical data.
> Potential for bias in patient datasets due to data collection methods and source populations.
> Risk of historical biases in reference medical knowledge.
> Inadequate documentation of preprocessing steps, data sources, and versioning.
- Recommendations: The subagent provided actionable recommendations for improving data governance and compliance, including enhancing documentation, implementing robust data quality checks, prioritizing bias detection and mitigation, and strengthening the data governance framework.

---

## Step 3: Technical Documentation Subagent

**Orchestrator Prompt:**  
> Now, I will call the Technical Documentation Subagent. To do this, I need access to DiagBot's technical documentation. Please provide this.

**User Input:**  
> Here you go .
> user attatches DiagBot_Technical_Documentation.pdf

**Expected  Output:**  
It seems the Technical Documentation Subagent requires more detailed information about the system architecture and technical specifications. The current documentation provides a high-level overview but lacks the depth required for a thorough assessment.

Please provide a more detailed description of DiagBot's system architecture, including:

> The specific algorithms and models used in the inference engine (e.g., rule-based system, statistical model, deep learning model).
> Details on the data preprocessing techniques used (e.g., normalization methods, categorical encoding schemes, handling of missing values).
> Information on the hardware and software infrastructure used to run DiagBot.
> Details on the system's interfaces and APIs.
> The system's intended use cases, limitations, and performance metrics.

**User Input:**  
> This information is not documented .

**Expected  Output:**  
The Technical Documentation Subagent is still requesting the missing information, even after being told it's not documented. This indicates that the subagent cannot proceed without that information. I will interpret this as an inability to assess compliance and will mark the Technical Documentation as Non-Compliant with a finding that essential documentation is missing.


---

## Step 4: Transparency & Information Provision Subagent

**Orchestrator Prompt:**  
> Now, I will call the Transparency & Information Provision Subagent. Based on the initial system description, DiagBot interacts directly with patients. To assess transparency, I need examples of user-AI conversation transcripts and any user-facing artifacts (e.g., labels, disclaimers, UI text) shown to end users.
.

**User Input:**  
> - Example interactions: same as above  
> - Disclaimer: “This system provides preliminary diagnostic suggestions. Always consult a licensed doctor before acting.”

**Expected Transparency Output:**  
- Finding: Disclaimers present but could be more prominently highlighted  
- **Verdict:** Partially Compliant  
- **Recommendations:** Emphasize disclaimers at the top of the interface

---

## Step 5: Human oversight Subagent

**Orchestrator Prompt:**  
> Now, based on the Risk Assessment and the findings so far, I will call the Human Oversight Subagent. To proceed, I need information on the human oversight mechanisms implemented in DiagBot. Specifically, I need to know how human experts can intervene in the system's operation, correct its outputs, and ensure its safety and compliance. Please provide details on these mechanisms.



**User Input:**  
> DiagBot has several human oversight mechanisms in place:

Expert Review: All high-risk or critical outputs flagged by DiagBot are routed to qualified medical professionals for review before any recommendations are finalized or communicated to patients.

Override Capability: Clinicians can manually override DiagBot’s preliminary diagnoses and suggested actions within the system interface, with all changes logged for audit purposes.

Audit Logs: Every interaction, including user input, system suggestions, and any human modifications, is logged to ensure traceability and accountability.

Escalation Procedures: The system automatically escalates ambiguous or high-risk cases to senior medical staff for immediate attention.

Periodic Oversight Reviews: Regular audits of DiagBot’s performance are conducted by clinical teams to assess accuracy, identify systemic biases, and ensure adherence to safety protocols.

Training & Feedback Loop: Human experts can provide feedback on incorrect or suboptimal outputs, which is used to refine the system’s rules and models over time.

**Expected  Output:**  
The Human Oversight Subagent requires clarification on the roles responsible for monitoring, reviewing, and intervening in DiagBot's operation.

Please provide a detailed list of the roles involved in human oversight, including their specific responsibilities and qualifications. For example:

> Medical Professionals: Review high-risk outputs, provide feedback, and override system suggestions. (Qualifications: MD, board-certified in relevant specialty)
> Senior Medical Staff: Handle escalated cases and provide guidance on complex or ambiguous situations. (Qualifications: MD, board-certified, with 10+ years of experience)
Clinical Teams: Conduct periodic performance audits, identify biases, and ensure adherence to safety protocols. (Composition: MDs, nurses, data scientists)
> Data Scientists/Engineers: Implement feedback from human experts, refine system models, and monitor system performance. (Qualifications: MSc/PhD in Computer Science, experience in machine learning)

**User Input:**  
we don't have roles defined yet

The Human Oversight Subagent is still requesting the missing information, even after being told it's not defined. This indicates that the subagent cannot proceed without it. I will interpret this as an inability to assess compliance and will mark Human Oversight as Non-Compliant with a finding that essential roles and responsibilities are missing.

---

## Step 6: Accuracy & Robustness Subagent

**Orchestrator Prompt:**  
> Next, I will call the Accuracy & Robustness Subagent. To proceed, I need information on how DiagBot's accuracy and robustness are evaluated and maintained. Please provide details on the metrics used to measure accuracy, the methods used to test robustness (e.g., stress tests, adversarial attacks), and the procedures for addressing any identified issues.
.

**User Input:**  
> DiagBot’s accuracy and robustness are maintained through a combination of metrics, testing, and remediation procedures. Diagnostic accuracy is measured by comparing the system’s preliminary diagnoses against confirmed clinical outcomes, while sensitivity, specificity, precision, and recall are tracked to ensure reliable detection of conditions and balanced coverage of possible diagnoses. Robustness is evaluated through stress testing under high loads, simulation of uncommon symptom combinations, and controlled adversarial inputs to identify potential vulnerabilities. Any errors, misclassifications, or system failures are logged and reviewed by both technical and clinical teams, with model or rule adjustments implemented as needed. Periodic re-evaluation against updated medical datasets ensures continuous improvement, and real-time monitoring dashboards track key performance metrics to maintain ongoing reliability and safety.

**Expected  Output:**  
The Accuracy & Robustness Subagent requires information on the measures in place to protect DiagBot from security threats or manipulation.

Please provide details on the security measures implemented to protect DiagBot, including:

Access Controls: Mechanisms to restrict access to the system and its data to authorized personnel.
Data Encryption: Methods used to encrypt sensitive data both in transit and at rest.
Intrusion Detection and Prevention Systems: Tools used to monitor and prevent unauthorized access or malicious activity.
Vulnerability Management: Processes for identifying and addressing security vulnerabilities in the system.
Security Audits: Regular assessments of the system's security posture.
Data Integrity Measures: Methods to ensure that the data used by the system has not been tampered.

**User Input:**  
DiagBot incorporates multiple layers of security to protect against threats and manipulation. Access to the system and its data is restricted through role-based access controls, ensuring only authorized personnel can view or modify sensitive information. Sensitive data is encrypted both in transit and at rest using industry-standard encryption protocols. The system is monitored by intrusion detection and prevention tools that track suspicious activity and block unauthorized access attempts. A vulnerability management program is in place to regularly identify, assess, and remediate potential security weaknesses. Additionally, security audits are conducted periodically to evaluate the system’s security posture and ensure compliance with best practices. To maintain data integrity, all inputs and critical datasets are logged, checksummed, and validated to detect any tampering or corruption, ensuring that DiagBot operates reliably and securely.

**Expected  Output:**  
Okay, I have received the output from the Accuracy & Robustness Subagent. Here's a summary:

Overall Compliance: Compliant
Key Findings: The subagent found that DiagBot has comprehensive approaches to accuracy, robustness, and security.
Recommendations: The subagent recommended formalizing and documenting specific metrics or thresholds for "high loads" in stress testing, the defined frequency/scope of "periodic re-evaluation" against updated datasets, and the scope/frequency of "security audits." It also suggested exploring independent, third-party validation or certification for key performance and security aspects.

## Step 7: Risk Managment and Monitoring Subagent

**Orchestrator Prompt:**  
> Now, I will call the Risk Management & Monitoring Subagent. To proceed, I need detailed information about DiagBot's risk management plan, including risk assessment procedures, mitigation strategies, and monitoring mechanisms. Please provide this information.
.

**User Input:**  
> DiagBot’s risk management plan is designed to identify, assess, mitigate, and monitor potential risks associated with its operation. Risk assessment procedures involve systematically evaluating the likelihood and potential impact of errors, misdiagnoses, and system failures. Mitigation strategies include implementing human oversight mechanisms, rule-based safety checks, and continuous model validation against updated medical datasets. High-risk outputs are flagged for expert review, and escalation procedures ensure that critical cases are promptly addressed by qualified clinicians. Monitoring mechanisms include real-time dashboards tracking system performance and diagnostic accuracy, automated logging of all user interactions, and periodic audits to detect emerging risks or patterns of concern. Together, these processes ensure that DiagBot operates safely, reliably, and in compliance with regulatory requirements.

**Expected  Output:**  
The Risk Management & Monitoring Subagent requires more specific information on how risks are identified, analyzed, and evaluated throughout DiagBot's AI lifecycle.

Please provide a detailed description of the risk management process, including:

Risk Identification:

What methods are used to identify potential risks (e.g., brainstorming, checklists, failure mode and effects analysis)?
Who is involved in the risk identification process (e.g., developers, clinicians, ethicists)?
How often is risk identification performed (e.g., at the beginning of the project, during development, continuously)?
Risk Analysis:

What techniques are used to analyze the identified risks (e.g., qualitative risk assessment, quantitative risk assessment, impact analysis)?
How are the likelihood and impact of each risk assessed?
What criteria are used to determine the severity of each risk?
Risk Evaluation:

How are the analyzed risks evaluated and prioritized?
What risk acceptance criteria are used (i.e., what level of risk is considered acceptable)?
How are risk decisions documented and communicated?

**User Input:**  
We try to find risks as we go. Developers and some other people look at the system sometimes. We look at risks using some methods, not sure exactly which. Then we sort of figure out which ones are worse. We just try to avoid the really bad ones. There aren’t really strict criteria, and we don’t document much. Mostly we just deal with things as they come up.

**Expected  Output:**  
The Risk Management & Monitoring Subagent continues to request information about the risk management process, even after being informed that it is informal and undocumented. This indicates that the subagent cannot proceed without a description of a systematic risk management process. Therefore, I will interpret this as an inability to assess compliance and will mark Risk Management & Monitoring as Non-Compliant with a finding that a systematic and documented risk management process is lacking.



## Step 8: Risk Conformity Assessment Subagent

**Orchestrator Prompt:**  
> The Conformity Assessment Subagent requires information on whether DiagBot has undergone a conformity assessment, and if so, the type and scope of the assessment.

Please provide details on any conformity assessment that has been performed on DiagBot, including:

Type of Assessment: Was the assessment conducted internally or by a third party?
Scope of Assessment: Which aspects of the system were assessed (e.g., data governance, technical documentation, risk management)?
Assessment Criteria: What standards or regulations were used to assess conformity?
Assessment Results: What were the findings of the assessment?
Corrective Actions: What actions were taken to address any identified non-conformities?
If no conformity assessment has been performed, please state that explicitly.


.

**User Input:**  
> we haven't had a chance to do that actually



**Expected  Output:**  

Okay, I have received the output from the Conformity Assessment Subagent. Here's a summary:

Overall Compliance: Non-Compliant
Key Findings: A conformity assessment has not been performed, which is a mandatory requirement for high-risk AI systems under the EU AI Act.
Recommendations: The subagent recommends initiating and completing either an internal conformity assessment (Module A) or a third-party assessment by a Notified Body (Modules B+C or H), ensuring all relevant requirements of the EU AI Act are met and properly documented.


## Step 9: Risk Conformity Assessment Subagent

**Orchestrator Prompt:**  

Finally, I will call the Post-Market Monitoring Subagent. To proceed, I need information on the plan for post-market monitoring of DiagBot. This includes how the system's performance will be monitored after deployment, how user feedback will be collected and analyzed, and how any identified issues will be addressed.

**User Input:**  

DiagBot’s post-market monitoring plan is designed to ensure ongoing safety, accuracy, and regulatory compliance after deployment. The system’s performance is continuously monitored through real-time dashboards tracking diagnostic accuracy, system uptime, and key reliability metrics. User feedback is collected directly through the application interface, including patient reports and clinician reviews, and is analyzed regularly to identify trends, errors, or areas for improvement. Any issues that are detected—whether from system logs, performance metrics, or user feedback—are promptly reviewed by the technical and clinical teams. Corrective actions, such as model updates, rule adjustments, or user notifications, are implemented as needed, and all post-market activities are documented to maintain transparency and support continuous improvement of DiagBot.

**Expected  Output:**  
The Post-Market Monitoring Subagent requires more specific information on the methods and algorithms used for analyzing performance data and user feedback.

Please provide details on the specific techniques used to analyze the data collected during post-market monitoring, including:

Statistical Analysis: Which statistical methods are used to analyze performance metrics (e.g., trend analysis, regression analysis, statistical process control)?
Natural Language Processing (NLP): Are NLP techniques used to analyze user feedback (e.g., sentiment analysis, topic modeling, text classification)?
Anomaly Detection: Are anomaly detection algorithms used to identify unusual patterns or outliers in the data?
Causal Inference: Are causal inference methods used to determine the root causes of identified issues?
Reporting and Visualization: How are the results of the analysis reported and visualized (e.g., dashboards, reports, alerts)?

**User Input:**  
During post-market monitoring, DiagBot’s performance data and user feedback are analyzed using a combination of statistical and computational techniques. Statistical methods such as trend analysis, regression analysis, and statistical process control are applied to track diagnostic accuracy, system reliability, and other key metrics over time. Natural Language Processing (NLP) techniques, including sentiment analysis, topic modeling, and text classification, are used to evaluate free-text user feedback from patients and clinicians. Anomaly detection algorithms identify unusual patterns or outliers in both performance metrics and user reports, helping to flag potential issues early. Where appropriate, causal inference methods are applied to determine the root causes of identified problems. The results of these analyses are communicated through dashboards, automated alerts, and periodic reports, providing actionable insights for technical and clinical teams to maintain and improve DiagBot’s performance and safety.

**Expected  Output:**  
Please describe the specific procedures for detecting and reporting incidents, failures, or non-compliance, including:

Detection Mechanisms: What specific triggers or thresholds are used to identify potential incidents, failures, or non-compliance events (e.g., specific error codes, performance degradation beyond a defined threshold, user complaints exceeding a certain volume)?
Reporting Channels: How are detected incidents, failures, or non-compliance events reported (e.g., automated alerts to specific personnel, manual reporting through a designated channel)?
Escalation Procedures: What are the procedures for escalating incidents based on their severity and potential impact (e.g., immediate notification of senior management for critical failures)?
Documentation: How are all detected incidents, failures, and non-compliance events documented, including their resolution and any corrective actions taken?

**User Input:**  
those are not available

**Expected  Output:**  
The Post-Market Monitoring Subagent requires a description of the post-market monitoring system. Since I have provided a description of the plan, and explicitly stated that the procedures for detecting incidents are not available, I will interpret this as the subagent's inability to assess compliance. I will mark Post-Market Monitoring as Non-Compliant with a finding that specific procedures for incident detection and reporting are lacking.



## Step 10: Final Result

Now that all relevant subagents have been called, I will compile a final compliance report.

EU AI Act Compliance Report: DiagBot

Overall Compliance Verdict: Non-Compliant

Overall Risk Level: High-Risk

Detailed Compliance Status:

Data Governance & Quality: Partially Compliant
Findings: Insufficient detail on missing value imputation, lack of consistency checks for categorical data, potential for bias in patient datasets, risk of historical biases in reference medical knowledge, inadequate documentation of preprocessing steps, data sources, and versioning.
Evidence: Dataset metadata provided by the user.
Recommendations: Enhance documentation, implement robust data quality checks, prioritize bias detection and mitigation, and strengthen the data governance framework.
Transparency & Information Provision: Partially Compliant
Findings: Lacks explicit AI disclosure, minimal guidance on system usage and output interpretation, outputs lack explainability, accessibility of the disclaimer needs further confirmation.
Evidence: Example interactions and disclaimer provided by the user.
Recommendations: Add an AI disclosure, provide more guidance on system usage, and explain the reasoning behind diagnostic suggestions.
Human Oversight: Non-Compliant
Findings: Essential roles and responsibilities for human oversight are missing.
Evidence: User stated that roles are not defined.
Recommendations: Define specific roles responsible for monitoring, reviewing, and intervening in DiagBot's operation.
Accuracy, Robustness & Security: Compliant
Findings: Comprehensive approaches to accuracy, robustness, and security.
Evidence: User provided details on accuracy metrics, robustness testing, and security measures.
Recommendations: Formalize and document specific metrics or thresholds for "high loads" in stress testing, the defined frequency/scope of "periodic re-evaluation," and the scope/frequency of "security audits."
Technical Documentation: Non-Compliant
Findings: Essential technical documentation is missing.
Evidence: The Technical Documentation Subagent was unable to proceed without a detailed description of the system architecture and technical specifications.
Recommendations: Create comprehensive technical documentation.
Risk Management & Monitoring: Non-Compliant
Findings: A systematic and documented risk management process is lacking.
Evidence: The Risk Management & Monitoring Subagent was unable to proceed without a description of a systematic risk management process. User stated that risk management is ad-hoc.
Recommendations: Implement a systematic and documented risk management process.
Conformity Assessment: Non-Compliant
Findings: A conformity assessment has not been performed, which is mandatory for high-risk AI systems.
Evidence: User stated that a conformity assessment has not been performed.
Recommendations: Initiate and complete a conformity assessment (internal or third-party).
Post-Market Monitoring: Non-Compliant
Findings: Specific procedures for incident detection and reporting are lacking.
Evidence: The Post-Market Monitoring Subagent was unable to proceed without details on incident detection and reporting procedures. User stated this information was not available.
Recommendations: Establish and document specific procedures for detecting and reporting incidents, failures, and non-compliance events.
Prioritized Recommendations:

Short Term:
Define and assign roles and responsibilities for human oversight.
Develop and document a systematic risk management process.
Establish specific procedures for detecting and reporting incidents, failures, and non-compliance during post-market monitoring.
Create comprehensive technical documentation.
Perform a conformity assessment.
Medium Term:
Enhance data governance practices, including improving documentation, implementing robust data quality checks, and prioritizing bias detection and mitigation.
Improve transparency by adding an AI disclosure, providing more guidance on system usage, and explaining the reasoning behind diagnostic suggestions.
Formalize and document specific metrics and thresholds for accuracy, robustness, and security measures.
Long Term:
Continuously monitor and improve the system's performance, safety, and compliance through ongoing data analysis, user feedback, and risk management activities.
Traceability Appendix:

Note: Timestamps have been omitted for brevity.

Risk Assessment Subagent:
Input: System description and example interactions.
Output: Risk level (High-Risk) and applicable compliance areas.
Data Governance & Quality Subagent:
Input: Dataset metadata in JSON format.
Output: Compliance status (Partially Compliant), findings, evidence, and recommendations related to data governance and quality.
Transparency & Information Provision Subagent:
Input: Example interactions and disclaimer.
Output: Compliance status (Partially Compliant), findings, evidence, and recommendations related to transparency and information provision.
Human Oversight Subagent:
Input: Description of human oversight mechanisms.
Output: Compliance status (Non-Compliant), findings, evidence, and recommendations related to human oversight.
Accuracy & Robustness Subagent:
Input: Details on accuracy metrics, robustness testing, and security measures.
Output: Compliance status (Compliant), findings, evidence, and recommendations related to accuracy, robustness, and security.
Technical Documentation Subagent:
Input: Technical documentation.
Output: Compliance status (Non-Compliant), findings, evidence, and recommendations related to technical documentation.
Risk Management & Monitoring Subagent:
Input: Description of the risk management plan.
Output: Compliance status (Non-Compliant), findings, evidence, and recommendations related to risk management and monitoring.
Conformity Assessment Subagent:
Input: Compliance status from other subagents and information on conformity assessment.
Output: Compliance status (Non-Compliant), findings, evidence, and recommendations related to conformity assessment.
Post-Market Monitoring Subagent:
Input: Description of the post-market monitoring plan.
Output: Compliance status (Non-Compliant), findings, evidence, and recommendations related to post-market monitoring.
This concludes the EU AI Act compliance report for DiagBot.


---
