# Agentic Governance Fabric (AGF) - EU AI Act Auditor

A sophisticated multi-agent AI governance system designed to audit and ensure compliance of AI systems with the **EU AI Act**. This framework leverages specialized sub-agents to orchestrate comprehensive compliance assessments across multiple governance domains.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Project Structure](#project-structure)
- [Architecture](#architecture)
- [Getting Started](#getting-started)
- [System Components](#system-components)
- [Compliance Assessment Workflow](#compliance-assessment-workflow)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

The **Agentic Governance Fabric (AGF)** is an AI governance platform that automates compliance auditing for AI systems against the EU AI Act. It uses a hierarchical multi-agent architecture where:

- A **Root Orchestrator Agent** manages the overall audit workflow
- **Nine specialized Sub-Agents** conduct targeted compliance assessments
- Each sub-agent focuses on a specific governance domain (risk, data, transparency, security, etc.)
- Results are aggregated into comprehensive compliance reports

This system ensures AI systems deployed in EU jurisdictions meet rigorous regulatory requirements while maintaining transparency, accountability, and risk management standards.

---

## âœ¨ Key Features

### Multi-Domain Compliance Assessment
- **Risk Assessment**: Identifies and categorizes AI system risks
- **Data Governance**: Ensures data quality, lineage, and compliance
- **Transparency & Information**: Validates user-facing disclosure requirements
- **Human Oversight**: Verifies human-in-the-loop mechanisms
- **Accuracy & Robustness**: Tests model performance and resilience
- **Technical Documentation**: Reviews system design and architecture documentation
- **Risk Management & Monitoring**: Validates risk mitigation strategies
- **Conformity Assessment**: Confirms overall EU AI Act compliance
- **Post-Market Monitoring**: Tracks ongoing compliance post-deployment

### Intelligent Orchestration
- Sequential agent execution for traceability and accountability
- Conditional sub-agent invocation based on risk assessment findings
- Strict input validation and schema enforcement
- Automated audit trail with timestamps and evidence references

### Structured Output
- Standardized compliance reporting (Compliant/Partially Compliant/Non-Compliant)
- Detailed findings with explicit evidence references
- Prioritized remediation recommendations
- Deferred evidence tracking for incomplete assessments

---

## ğŸ—ï¸ Project Structure

```
Agentic-Governance-Fabric-AGF-/
â”œâ”€â”€ eu_ai_act_auditor/
â”‚   â”œâ”€â”€ agent.py                    # Root orchestrator agent
â”‚   â”œâ”€â”€ prompt.py                   # Orchestrator instructions and workflows
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ .env                        # Environment configuration
â”‚   â””â”€â”€ sub_agents/
â”‚       â”œâ”€â”€ risk_assesor/           # Risk assessment sub-agent
â”‚       â”œâ”€â”€ data_governor/          # Data governance sub-agent
â”‚       â”œâ”€â”€ transparency_assesor/   # Transparency sub-agent
â”‚       â”œâ”€â”€ accuracy_robustness_security/  # Security & accuracy sub-agent
â”‚       â”œâ”€â”€ conformity_assessment/  # Conformity assessment sub-agent
â”‚       â”œâ”€â”€ human_oversight/        # Human oversight sub-agent
â”‚       â”œâ”€â”€ post_market_monitoring/ # Post-market monitoring sub-agent
â”‚       â”œâ”€â”€ technical_documentation/# Documentation sub-agent
â”‚       â””â”€â”€ risk_management_monitoring/  # Risk management sub-agent
â”œâ”€â”€ readme.md                       # This file
â””â”€â”€ .gitattributes

```

---

## ğŸ§  Architecture

### Multi-Agent System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Root EU AI Act Auditor Agent          â”‚
â”‚   (Orchestrator - Gemini 2.0 Flash)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚            â”‚             â”‚            â”‚             â”‚               â”‚              â”‚
    â–¼            â–¼            â–¼             â–¼            â–¼             â–¼               â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Risk  â”‚  â”‚  Data  â”‚  â”‚Transparentâ”‚ â”‚Human  â”‚  â”‚Accuracy  â”‚  â”‚Conformity â”‚  â”‚ Technicalâ”‚  â”‚Post-Market  â”‚
â”‚ Assess â”‚  â”‚ Govern â”‚  â”‚     &     â”‚ â”‚Oversightâ”‚ â”‚Robustnessâ”‚  â”‚Assessment â”‚  â”‚Document  â”‚  â”‚Monitoring  â”‚
â”‚        â”‚  â”‚        â”‚  â”‚ Informationâ”‚ â”‚       â”‚  â”‚Security  â”‚  â”‚          â”‚  â”‚          â”‚  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–²           â–²            â–²             â–²            â–²             â–²               â–²              â–²
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          Conditional Invocation Based on Risk Profile
```

### Workflow Execution Model

1. **Initialization**: Root agent receives audit request
2. **Risk Assessment**: Mandatory first stageâ€”identifies risk level and compliance areas
3. **Conditional Routing**: Based on risk output, determine which sub-agents to activate
4. **Sequential Execution**: Each sub-agent executes and validates findings
5. **Aggregation**: Compile results into final compliance report
6. **Output**: Standardized compliance assessment with remediation roadmap

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9+
- Google Cloud SDK
- Google AI SDK (google-adk-agents)
- Git

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/ZaidSaid12/Agentic-Governance-Fabric-AGF-.git
cd Agentic-Governance-Fabric-AGF-
```

2. **Create a Python virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables:**
```bash
cp .env.example .env
# Edit .env with your API keys and configuration
```

---

## ğŸ”§ System Components

### Root Orchestrator Agent (`agent.py`)

The orchestrator manages the entire audit lifecycle:
- **Model**: Gemini 2.0 Flash
- **Role**: Coordinate sub-agents and enforce compliance workflow
- **Tools**: Agent tools for each specialized sub-agent

**Key Responsibilities:**
- Enforce sequential execution
- Validate inputs and outputs
- Maintain audit trail
- Generate compliance summary

### Sub-Agents Overview

#### 1. **Risk Assessment Sub-Agent**
- **Purpose**: Analyze AI system risk profile
- **Input**: System description, example conversations
- **Output**: Risk level (High/Medium/Low), affected compliance domains
- **Status**: Mandatoryâ€”executed first

#### 2. **Data Governance Sub-Agent**
- **Purpose**: Ensure data quality, provenance, and compliance
- **Input**: Dataset metadata, data lineage, source documentation
- **Output**: Data quality findings, compliance with data processing requirements

#### 3. **Transparency & Information Sub-Agent**
- **Purpose**: Validate user-facing disclosures and transparency
- **Input**: Example user-AI conversations, user-facing artifacts (labels, disclaimers)
- **Restriction**: Does NOT receive internal architecture or developer documentation
- **Output**: Transparency compliance findings, disclosure gaps

#### 4. **Human Oversight Sub-Agent**
- **Purpose**: Verify human-in-the-loop mechanisms
- **Input**: Governance model, human review procedures
- **Output**: Human oversight compliance findings

#### 5. **Accuracy & Robustness Sub-Agent**
- **Purpose**: Assess model performance and security resilience
- **Input**: Model performance metrics, security testing reports
- **Output**: Accuracy, robustness, and security findings

#### 6. **Technical Documentation Sub-Agent**
- **Purpose**: Review system design and implementation documentation
- **Input**: Technical architecture, algorithm descriptions, system design
- **Output**: Documentation completeness and clarity findings

#### 7. **Risk Management & Monitoring Sub-Agent**
- **Purpose**: Validate risk mitigation strategies
- **Input**: Risk management procedures, monitoring logs
- **Output**: Risk management compliance findings

#### 8. **Conformity Assessment Sub-Agent**
- **Purpose**: Synthesize all findings into conformity determination
- **Input**: Aggregated sub-agent outputs
- **Output**: Overall EU AI Act conformity status

#### 9. **Post-Market Monitoring Sub-Agent**
- **Purpose**: Track ongoing compliance after deployment
- **Input**: Production logs, user feedback, performance monitoring
- **Output**: Post-deployment compliance findings

---

## ğŸ“Š Compliance Assessment Workflow

### Audit Execution Flow

```
1. START: User submits AI system for audit
   â†“
2. RISK ASSESSMENT (Mandatory)
   - Analyze system architecture
   - Identify risk level
   - Determine relevant compliance domains
   â†“
3. CONDITIONAL ROUTING
   - Route to applicable sub-agents based on risk profile
   - Skip non-applicable domains
   â†“
4. SEQUENTIAL SUB-AGENT EXECUTION
   For each applicable domain:
   a. Request required inputs from user
   b. Validate input schema and completeness
   c. Execute specialized sub-agent
   d. Collect findings and evidence
   e. Record results with timestamp
   â†“
5. OUTPUT STANDARDIZATION
   Each sub-agent returns:
   - Compliance Status: Compliant/Partially Compliant/Non-Compliant
   - Findings: Detailed compliance issues
   - Evidence: References (transcript quotes, metrics, documentation)
   - Recommendations: Prioritized remediation steps
   â†“
6. AGGREGATION & SYNTHESIS
   - Compile all sub-agent findings
   - Generate executive summary
   - Create remediation roadmap
   â†“
7. REPORT GENERATION
   - Output: Comprehensive compliance assessment
   - Recommendations: Prioritized action items
   - Timeline: Suggested remediation schedule
   â†“
8. END: Audit complete with compliance determination
```

### Input Validation Gates

Each sub-agent enforces strict input requirements:

| Sub-Agent | Required Input | Optional Input | Forbidden Input |
|-----------|---|---|---|
| Risk Assessment | System description | Example conversations | N/A |
| Data Governance | Dataset metadata | Data lineage | N/A |
| Transparency | User conversations | User-facing artifacts | Internal docs, architecture |
| Human Oversight | Governance procedures | Review logs | N/A |
| Accuracy & Robustness | Performance metrics | Test reports | N/A |
| Technical Documentation | Architecture docs | Algorithm descriptions | N/A |
| Risk Management | Risk procedures | Monitoring logs | N/A |
| Conformity Assessment | Sub-agent outputs | N/A | N/A |
| Post-Market Monitoring | Production data | User feedback | N/A |

---

## ğŸ“‹ Requirements

### Python Packages
- `google-cloud-aiplatform` - Google Cloud AI services
- `google-adk-agents` - Agent development kit
- `python-dotenv` - Environment configuration
- Additional dependencies listed in `requirements.txt`

### API Access
- Google Cloud Project with AI Platform enabled
- Gemini API access
- Appropriate service account credentials

---

## ğŸ”Œ Configuration

### Environment Variables (`.env`)

```env
# Google Cloud Configuration
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json

# Gemini Configuration
GEMINI_API_KEY=your-api-key
GEMINI_MODEL=gemini-2.0-flash

# Audit Configuration
AUDIT_TIMEOUT=3600  # seconds
AUDIT_LOG_LEVEL=INFO
```

---

## ğŸ’» Usage

### Basic Audit

```python
from eu_ai_act_auditor.agent import root_agent

# Run audit with user-provided AI system information
response = root_agent.generate_content("""
Please audit my AI-powered recommendation system for EU AI Act compliance.
System description: [Your system details]
""")

print(response.text)
```

### With Custom Configuration

```python
from eu_ai_act_auditor.agent import root_agent

audit_request = """
System: Customer support chatbot
Risk Profile: Medium (NLP-based, user interaction)
Please conduct a full compliance audit.
"""

response = root_agent.generate_content(audit_request)
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Make your changes with clear commit messages
4. Ensure code follows project style guidelines
5. Submit a pull request with detailed description

### Areas for Contribution
- New sub-agent implementations
- Enhanced risk assessment algorithms
- Additional EU AI Act compliance domains
- Improved documentation and examples
- Performance optimizations

---

## ğŸ“œ License

This project is licensed under the MIT License. See LICENSE file for details.

---

## ğŸ“ Support & Contact

For issues, questions, or suggestions:
- Create an issue on GitHub
- Contact the project owner: 
    - Esraa Abdelmotteleb
    - Zaid Said 
    - Karim Hesham

---

## ğŸ”— References

- [EU AI Act](https://ec.europa.eu/newsroom/desca/items/676255/en)
- [Google AI Agents Documentation](https://ai.google.dev)
- [AI Governance Best Practices](https://www.ai-governance.org)

---

## Disclaimer

This governance framework is provided as-is for compliance assessment purposes. It should be used in conjunction with legal and compliance expertise to ensure full adherence to EU AI Act requirements. Always consult with legal advisors for definitive compliance determinations.

---

**Last Updated**: November 2025  
**Version**: 1.0.0  
**Status**: Active Development